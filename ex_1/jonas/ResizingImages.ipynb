{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "from numpy import interp, ndarray\n",
    "from timeit import default_timer as timer\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "image_names = []\n",
    "for filename in glob.glob('images/*.jpg'): #assuming jpg\n",
    "    im=Image.open(filename)\n",
    "    image_names.append(im.filename)\n",
    "    image_list.append(np.array(im))\n",
    "    #im.show()\n",
    "#print(len(image_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize a list of images by a factor of 5\n",
    "def resize(images):\n",
    "    resized = []\n",
    "    for im in images:\n",
    "        start = timer()\n",
    "        #print(im.shape)\n",
    "        result = np.zeros((int(im.shape[0]/5), int(im.shape[1]/5), im.shape[2]))\n",
    "        #print(result.shape)\n",
    "        for dim in range(im.shape[-1]):\n",
    "            for row in range(int(im.shape[0]/5)):\n",
    "                for col in range(int(im.shape[1]/5)):\n",
    "                    square = []\n",
    "                    for i in range(5):\n",
    "                        for j in range(5):\n",
    "                            square.append(im[5*row+i, 5*col+j, dim])\n",
    "                    #result[row, col, dim] = sum(square)/25 #area average\n",
    "                    square.sort()\n",
    "                    result[row, col, dim] = square[12] #median\n",
    "        resized.append(result)\n",
    "        end = timer()\n",
    "        print(end - start)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Choosing the median instead of the average reduced the run time by about 28% (from 1.33s to 0.96s per image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9118854999978794\n",
      "0.8998844000016106\n"
     ]
    }
   ],
   "source": [
    "resized_images = resize(image_list)\n",
    "for im in resized_images:\n",
    "    Image.fromarray(np.uint8(im)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening downscaled images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since scaling down the image might result in a somewhat less sharp image (especially when using area average or the mean as I did in the implementation above), I tried to apply a sharpening filter on the small image to counter this effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clip outliers to rgb range\n",
    "cut = lambda t : max(min(t, 256), 0)\n",
    "fnc = np.vectorize(cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(images):\n",
    "    #sharpen = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "    #sharpen = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    sharpen = np.array([[0,-0.125,0], [-0.125,1.25,-0.125], [0,-0.125,0]])\n",
    "    print(sharpen)\n",
    "    results = []\n",
    "    for im in images:\n",
    "        temp = np.copy(im)\n",
    "        for dim in range(im.shape[-1]):\n",
    "            for row in range(int(im.shape[0])-2):\n",
    "                for col in range(int(im.shape[1])-2):\n",
    "                    accumulator = 0.0\n",
    "                    for i in range(3):\n",
    "                        for j in range(3):\n",
    "                            #print(im[row+i, col+j, dim], sharpen[i,j])\n",
    "                            accumulator += im[row+i, col+j, dim]*sharpen[i,j]\n",
    "                    temp[row+1, col+1, dim] = accumulator\n",
    "                    #print(row, col, dim, accumulator)\n",
    "        results.append(fnc(temp))                   \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Only the last sharpening kernel yielded usable results. The other images had some prominent artifacts. However, this kernel darkens the image noticeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    -0.125  0.   ]\n",
      " [-0.125  1.25  -0.125]\n",
      " [ 0.    -0.125  0.   ]]\n"
     ]
    }
   ],
   "source": [
    "final_images = kernel(resized_images)\n",
    "for im in final_images:\n",
    "    Image.fromarray(np.uint8(im)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the first two sharpening kernels left some artifacts on the image (i.e. some value were well beyond the rgb range), the following loop tries to readjust the range (i.e. map the range of image values back to rgb values). Unfortunately, this did not significantly improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to map range of image values to rgb scale\n",
    "for im in final_images:\n",
    "    liste = ndarray.tolist(im)\n",
    "    liste = [interp(x,[np.amin(im),np.max(im)],[0,256]) for x in liste]\n",
    "    final = np.array(liste)\n",
    "    Image.fromarray(np.uint8(final)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for l in range(len(image_list)):\n",
    "    resized_images[l] = Image.fromarray(np.uint8(resized_images[l]))\n",
    "    resized_images[l].filename = image_names[l]\n",
    "any(im.save(str(im.filename).replace('600x900', '120x180')) for im in resized_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function uses stride = 1 and padding = 0. It assumes a 2D kernel and it  will leave a border of $\\lfloor \\frac{size(kernel)}{2} \\rfloor$ containing unchanged pixels (which should be fine for small kernel, e.g. for size 3x3 only a single pixel border remains). Alternatively, one could also remove these pixels from the image, making the transformed image slightly smaller. \n",
    "\n",
    "Note: As you can see the following function is very similar to the sharpening kernel from 1a. The major differences are that this function takes a kernel as input parameter, works with different sized kernels and only applies the kernel to a single image (not a list of images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolute(image, kernel):\n",
    "    start = timer()\n",
    "    new_image = np.copy(im)\n",
    "    offset = int(math.ceil(len(kernel)/2))\n",
    "    for dim in range(image.shape[-1]):\n",
    "        for row in range(int(image.shape[0])-2*offset):\n",
    "             for col in range(int(image.shape[1])-2*offset):\n",
    "                accumulator = 0.0\n",
    "                for i in range(len(kernel)):\n",
    "                    for j in range(len(kernel)):\n",
    "                        #print(im[row+i, col+j, dim], sharpen[i,j])\n",
    "                        accumulator += image[row+i, col+j, dim]*kernel[i,j]\n",
    "                new_image[row+offset, col+offset, dim] = accumulator\n",
    "                #print(row, col, dim, accumulator)\n",
    "    end = timer()\n",
    "    print(end - start)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.0628902999997\n",
      "137.71480560000055\n"
     ]
    }
   ],
   "source": [
    "#box_blur = np.array([[1/9,1/9,1/9], [1/9,1/9,1/9], [1/9,1/9,1/9]])\n",
    "#gaussian_blur = np.array([[1/16,1/8,1/16], [1/8,1/4,1/8], [1/16,1/8,1/16]])\n",
    "gaussian_blur5 = np.array([[1/256,4/256,6/256,4/256,1/256], [4/256,16/256,24/256,16/256,4/256], \n",
    "                            [6/256,24/256,36/256,24/256,6/256], [4/256,16/256,24/256,16/256,4/256],\n",
    "                            [1/256,4/256,6/256,4/256,1/256]])\n",
    "blurred_images = []\n",
    "for im in image_list:\n",
    "    blurred_images.append(convolute(im, gaussian_blur5)) #aprox runtime per image: 150s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in blurred_images:\n",
    "    Image.fromarray(np.uint8(im)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.91453080000065\n",
      "59.00540019999971\n"
     ]
    }
   ],
   "source": [
    "#edge_detection = np.array([[1,0,-1], [0,0,0], [-1,0,1]])\n",
    "edge_detection = np.array([[-1,-1,-1], [-1,8,-1], [-1,-1,-1]])\n",
    "contour_images = []\n",
    "for im in image_list:\n",
    "    contour_images.append(convolute(im, edge_detection)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in contour_images:\n",
    "    Image.fromarray(np.uint8(im)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobel kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.93771959999867\n",
      "50.31189169999925\n",
      "52.228896800002985\n",
      "51.57797760000176\n"
     ]
    }
   ],
   "source": [
    "kx = np.array([[-0.25,0,1], [-0.5,0,0.5], [-0.25,0,0.25]])\n",
    "ky = np.array([[-0.25,-0.5,-0.25], [0,0,0], [0.25,0.5,0.25]])\n",
    "sobel_images = []\n",
    "for im in image_list:\n",
    "    sobel_images.append(convolute(convolute(im, kx), ky)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in sobel_images:\n",
    "    Image.fromarray(np.uint8(im)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Applying the sobel kernels did actually return an image with more distinct contour lines. However, I think the way I implemented them is wrong, because I apply the two kernels one after the other while the intended way is to apply both kernels on the original image and then somehow combine the two images together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for l in range(len(image_list)):\n",
    "    blurred_images[l] = Image.fromarray(np.uint8(blurred_images[l]))\n",
    "    blurred_images[l].filename = image_names[l]\n",
    "    contour_images[l] = Image.fromarray(np.uint8(contour_images[l]))\n",
    "    contour_images[l].filename = image_names[l]\n",
    "    sobel_images[l] = Image.fromarray(np.uint8(sobel_images[l]))\n",
    "    sobel_images[l].filename = image_names[l]\n",
    "any(im.save(str(im.filename).replace('600x900', 'blurred')) for im in blurred_images)\n",
    "any(im.save(str(im.filename).replace('600x900', 'edges')) for im in contour_images)\n",
    "any(im.save(str(im.filename).replace('600x900', 'sobel')) for im in sobel_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
